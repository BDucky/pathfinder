import { defineStore } from 'pinia'
import { GoogleGenerativeAI } from '@google/generative-ai'
import Groq from 'groq-sdk'
import { getActiveMode, apiRequest } from '../config/api'

export const useChatStore = defineStore('chat', {
  state: () => ({
    messages: [],
    isTyping: false,
    error: null,
    aiProvider: 'gemini', // 'gemini' or 'groq'
    chatSession: null, // For Gemini chat history
  }),

  actions: {
    /**
     * Initialize chat with system prompt based on learning path
     */
    initializeChat(learningPath) {
      const systemPrompt = this.generateSystemPrompt(learningPath)
      
      // Clear previous messages and start fresh
      this.messages = [
        {
          id: Date.now(),
          role: 'assistant',
          content: `Xin chÃ o! ğŸ‘‹ TÃ´i lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a báº¡n. TÃ´i sáº½ Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong lá»™ trÃ¬nh há»c **${learningPath?.topic || 'cá»§a báº¡n'}**.

TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:
ğŸ“š Giáº£i thÃ­ch khÃ¡i niá»‡m vÃ  thuáº­t ngá»¯
ğŸ’¡ Gá»£i Ã½ bÃ i táº­p thá»±c hÃ nh
ğŸ¯ ÄÃ¡nh giÃ¡ tiáº¿n Ä‘á»™ há»c táº­p
ğŸ” TÃ³m táº¯t ná»™i dung video
â“ Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» chá»§ Ä‘á» Ä‘ang há»c

HÃ£y há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬ báº¡n cáº§n! ğŸ˜Š`,
          timestamp: new Date().toISOString()
        }
      ]

      // Store system context for AI
      this.systemContext = systemPrompt
      this.learningPathContext = learningPath
    },

    /**
     * Generate system prompt with learning path context
     */
    generateSystemPrompt(learningPath) {
      if (!learningPath) {
        return `Báº¡n lÃ  má»™t trá»£ lÃ½ há»c táº­p AI thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p. 
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  há»— trá»£ há»c viÃªn trong quÃ¡ trÃ¬nh há»c táº­p, giáº£i Ä‘Ã¡p tháº¯c máº¯c, 
vÃ  Ä‘Æ°a ra lá»i khuyÃªn há»¯u Ã­ch. HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n vÃ  dá»… hiá»ƒu.`
      }

      const currentWeek = learningPath.weeks?.find(w => !w.completed)
      const completedWeeks = learningPath.weeks?.filter(w => w.completed) || []
      
      return `Báº¡n lÃ  má»™t trá»£ lÃ½ há»c táº­p AI chuyÃªn nghiá»‡p, Ä‘ang há»— trá»£ há»c viÃªn trong lá»™ trÃ¬nh há»c táº­p cÃ¡ nhÃ¢n hÃ³a.

## ThÃ´ng tin lá»™ trÃ¬nh há»c táº­p:
- **Chá»§ Ä‘á»**: ${learningPath.topic}
- **TrÃ¬nh Ä‘á»™**: ${learningPath.level}
- **Tá»•ng thá»i gian**: ${learningPath.totalWeeks} tuáº§n
- **Giá» há»c má»—i tuáº§n**: ${learningPath.hoursPerWeek} giá»
- **Tiáº¿n Ä‘á»™ hiá»‡n táº¡i**: ${completedWeeks.length}/${learningPath.weeks?.length || 0} tuáº§n Ä‘Ã£ hoÃ n thÃ nh

${currentWeek ? `## Tuáº§n hiá»‡n táº¡i (Tuáº§n ${currentWeek.weekNumber}): ${currentWeek.title}
**Má»¥c tiÃªu**:
${currentWeek.objectives?.map(obj => `- ${obj}`).join('\n')}

**Chá»§ Ä‘á» há»c**:
${currentWeek.topics?.map(topic => `- ${topic}`).join('\n')}` : ''}

## Vai trÃ² cá»§a báº¡n:
1. Giáº£i thÃ­ch khÃ¡i niá»‡m vÃ  thuáº­t ngá»¯ liÃªn quan Ä‘áº¿n ${learningPath.topic}
2. ÄÆ°a ra vÃ­ dá»¥ thá»±c táº¿ vÃ  dá»… hiá»ƒu
3. Gá»£i Ã½ bÃ i táº­p vÃ  dá»± Ã¡n thá»±c hÃ nh phÃ¹ há»£p vá»›i trÃ¬nh Ä‘á»™ ${learningPath.level}
4. ÄÃ¡nh giÃ¡ tiáº¿n Ä‘á»™ vÃ  Ä‘á»™ng viÃªn há»c viÃªn
5. Tráº£ lá»i cÃ¢u há»i vá» ná»™i dung Ä‘ang há»c
6. TÃ³m táº¯t video vÃ  tÃ i liá»‡u há»c táº­p

## NguyÃªn táº¯c giao tiáº¿p:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
- Ngáº¯n gá»n, sÃºc tÃ­ch (3-5 cÃ¢u trá»« khi cáº§n giáº£i thÃ­ch chi tiáº¿t)
- Sá»­ dá»¥ng emoji phÃ¹ há»£p Ä‘á»ƒ tÄƒng tÃ­nh thÃ¢n thiá»‡n
- Khuyáº¿n khÃ­ch há»c viÃªn thá»±c hÃ nh vÃ  Ä‘áº·t cÃ¢u há»i
- ÄÆ°a ra vÃ­ dá»¥ code khi cáº§n thiáº¿t (vá»›i syntax highlighting)

HÃ£y trá»Ÿ thÃ nh ngÆ°á»i Ä‘á»“ng hÃ nh tuyá»‡t vá»i nháº¥t cho há»c viÃªn!`
    },

    /**
     * Send message to AI and get response
     * Supports both backend API and client-side mode
     */
    async sendMessage(userMessage) {
      if (!userMessage.trim()) return

      // Add user message
      const userMsg = {
        id: Date.now(),
        role: 'user',
        content: userMessage,
        timestamp: new Date().toISOString()
      }
      this.messages.push(userMsg)

      this.isTyping = true
      this.error = null

      try {
        const mode = getActiveMode()
        let aiResponse

        if (mode === 'backend') {
          // Use backend API
          const conversationHistory = this.messages
            .slice(0, -1) // Exclude the message we just added
            .filter(m => !m.isError)
            .map(m => ({ role: m.role, content: m.content }))

          const result = await apiRequest('/chat', {
            message: userMessage,
            provider: this.aiProvider,
            systemContext: this.systemContext,
            conversationHistory
          })

          aiResponse = result.response

        } else {
          // Use client-side API keys
          if (this.aiProvider === 'gemini') {
            aiResponse = await this.sendToGemini(userMessage)
          } else if (this.aiProvider === 'groq') {
            aiResponse = await this.sendToGroq(userMessage)
          } else {
            throw new Error('Invalid AI provider selected')
          }
        }

        // Add AI response
        const assistantMsg = {
          id: Date.now() + 1,
          role: 'assistant',
          content: aiResponse,
          timestamp: new Date().toISOString()
        }
        this.messages.push(assistantMsg)

        // Save to localStorage
        this.saveMessages()

      } catch (error) {
        console.error('Chat error:', error)
        this.error = error.message || 'ÄÃ£ xáº£y ra lá»—i khi giao tiáº¿p vá»›i AI'
        
        // Add error message
        this.messages.push({
          id: Date.now() + 1,
          role: 'assistant',
          content: `âŒ Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ yÃªu cáº§u: ${this.error}\n\nVui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh hoáº·c thá»­ láº¡i sau.`,
          timestamp: new Date().toISOString(),
          isError: true
        })
      } finally {
        this.isTyping = false
      }
    },

    /**
     * Send message to Google Gemini API
     */
    async sendToGemini(message) {
      const apiKey = localStorage.getItem('gemini_api_key')
      if (!apiKey) {
        throw new Error('Gemini API key not found. Please configure it in settings.')
      }

      const genAI = new GoogleGenerativeAI(apiKey)
      const model = genAI.getGenerativeModel({ 
        model: 'gemini-2.5-pro',
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 1024,
        }
      })

      // Initialize chat with history if not exists
      if (!this.chatSession) {
        this.chatSession = model.startChat({
          history: this.convertMessagesToGeminiHistory(),
          generationConfig: {
            maxOutputTokens: 1024,
          },
        })
      }

      // Send message with system context
      const contextualMessage = `${this.systemContext}\n\n---\n\nHá»c viÃªn há»i: ${message}`
      const result = await this.chatSession.sendMessage(contextualMessage)
      const response = await result.response
      return response.text()
    },

    /**
     * Send message to Groq API
     */
    async sendToGroq(message) {
      const apiKey = localStorage.getItem('groq_api_key')
      if (!apiKey) {
        throw new Error('Groq API key not found. Please configure it in settings.')
      }

      const groq = new Groq({ 
        apiKey,
        dangerouslyAllowBrowser: true // Enable browser usage
      })

      // Build conversation history
      const messages = [
        {
          role: 'system',
          content: this.systemContext || 'Báº¡n lÃ  má»™t trá»£ lÃ½ há»c táº­p AI thÃ¢n thiá»‡n.'
        },
        ...this.convertMessagesToGroqHistory(),
        {
          role: 'user',
          content: message
        }
      ]

      const chatCompletion = await groq.chat.completions.create({
        messages,
        model: 'llama-3.1-8b-instant', // Fast and powerful
        temperature: 0.7,
        max_tokens: 1024,
        top_p: 1,
        stream: false
      })

      return chatCompletion.choices[0]?.message?.content || 'No response'
    },

    /**
     * Convert messages to Gemini chat history format
     */
    convertMessagesToGeminiHistory() {
      // Only include recent messages (last 10) to avoid token limits
      const recentMessages = this.messages.slice(-10).filter(m => !m.isError && m.role !== 'system')
      
      return recentMessages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }]
      }))
    },

    /**
     * Convert messages to Groq chat history format
     */
    convertMessagesToGroqHistory() {
      // Only include recent messages (last 10) to avoid token limits
      const recentMessages = this.messages.slice(-10).filter(m => !m.isError && m.role !== 'system')
      
      return recentMessages.map(msg => ({
        role: msg.role,
        content: msg.content
      }))
    },

    /**
     * Switch AI provider
     */
    switchProvider(provider) {
      if (provider !== 'gemini' && provider !== 'groq') {
        console.error('Invalid provider:', provider)
        return
      }

      this.aiProvider = provider
      this.chatSession = null // Reset chat session when switching

      // Save preference
      localStorage.setItem('preferred_ai_provider', provider)
    },

    /**
     * Clear chat history
     */
    clearChat() {
      this.messages = []
      this.chatSession = null
      this.error = null
      localStorage.removeItem('chat_messages')
    },

    /**
     * Save messages to localStorage
     */
    saveMessages() {
      try {
        localStorage.setItem('chat_messages', JSON.stringify(this.messages))
      } catch (error) {
        console.error('Failed to save chat messages:', error)
      }
    },

    /**
     * Load messages from localStorage
     */
    loadMessages() {
      try {
        const saved = localStorage.getItem('chat_messages')
        if (saved) {
          this.messages = JSON.parse(saved)
        }
      } catch (error) {
        console.error('Failed to load chat messages:', error)
      }
    },

    /**
     * Load AI provider preference
     */
    loadProviderPreference() {
      const saved = localStorage.getItem('preferred_ai_provider')
      if (saved && (saved === 'gemini' || saved === 'groq')) {
        this.aiProvider = saved
      }
    }
  },

  getters: {
    hasMessages: (state) => state.messages.length > 0,
    messageCount: (state) => state.messages.length,
    lastMessage: (state) => state.messages[state.messages.length - 1] || null
  }
})

